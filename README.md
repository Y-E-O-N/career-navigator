# ğŸ“Š Job Market Analyzer

ì±„ìš© ì‹œì¥ ë¶„ì„ ë° ì»¤ë¦¬ì–´ ë¡œë“œë§µ ìƒì„± ì‹œìŠ¤í…œ

ë§¤ì¼ ì£¼ìš” ì±„ìš© ì‚¬ì´íŠ¸ë¥¼ í¬ë¡¤ë§í•˜ì—¬ ì‹œì¥ íŠ¸ë Œë“œë¥¼ ë¶„ì„í•˜ê³ , AI ê¸°ë°˜ ë§ì¶¤í˜• ì»¤ë¦¬ì–´ ë¡œë“œë§µì„ ìƒì„±í•©ë‹ˆë‹¤.

## âœ¨ ì£¼ìš” ê¸°ëŠ¥

- **ë©€í‹° ì‚¬ì´íŠ¸ í¬ë¡¤ë§**: LinkedIn, ì›í‹°ë“œ, ì¡ì½”ë¦¬ì•„, ì‚¬ëŒì¸, ë¡œì¼“í€ì¹˜
- **ì‹œì¥ íŠ¸ë Œë“œ ë¶„ì„**: ì±„ìš© ë™í–¥, ìŠ¤í‚¬ ìˆ˜ìš”, ê¸°ì—…ë³„ ì±„ìš© í˜„í™©
- **íšŒì‚¬ í‰íŒ ì¡°ì‚¬**: ì¡í”Œë˜ë‹› í‰ì , ë‰´ìŠ¤, ì¢…í•© í‰ê°€
- **AI ì»¤ë¦¬ì–´ ë¡œë“œë§µ**: Claude/GPT ê¸°ë°˜ 3/6ê°œì›” í•™ìŠµ ë¡œë“œë§µ
- **ìë™ ìŠ¤ì¼€ì¤„ë§**: ë§¤ì¼ ì§€ì • ì‹œê°„ ìë™ ì‹¤í–‰
- **ë¦¬í¬íŠ¸ ìƒì„±**: Markdown, HTML, JSON í˜•ì‹

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. ì„¤ì¹˜

```bash
# ì €ì¥ì†Œ í´ë¡ 
git clone https://github.com/your-repo/job-market-analyzer.git
cd job-market-analyzer

# ê°€ìƒí™˜ê²½ ìƒì„± (ê¶Œì¥)
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt
```

### 2. í™˜ê²½ ì„¤ì •

```bash
# .env íŒŒì¼ ìƒì„±
cp .env.example .env

# ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ ì§ì ‘ ì„¤ì •
export ANTHROPIC_API_KEY=your_api_key  # LLM ë¶„ì„ìš© (ì„ íƒ)
export DB_TYPE=sqlite                   # ë˜ëŠ” postgresql
```

### 3. ì‹¤í–‰

```bash
# ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (í¬ë¡¤ë§ â†’ ë¶„ì„ â†’ ë¦¬í¬íŠ¸)
python main.py all

# í¬ë¡¤ë§ë§Œ ì‹¤í–‰
python main.py crawl

# ë¶„ì„ë§Œ ì‹¤í–‰
python main.py analyze

# ë¦¬í¬íŠ¸ ìƒì„±
python main.py report

# íŠ¹ì • íšŒì‚¬ ë¶„ì„
python main.py company "ì¹´ì¹´ì˜¤"

# ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ (ë§¤ì¼ ìë™ ì‹¤í–‰)
python main.py schedule
```

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
job_market_analyzer/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py      # ì„¤ì • ê´€ë¦¬
â”œâ”€â”€ crawlers/
â”‚   â”œâ”€â”€ base_crawler.py       # í¬ë¡¤ëŸ¬ ë² ì´ìŠ¤ í´ë˜ìŠ¤
â”‚   â”œâ”€â”€ linkedin_crawler.py   # LinkedIn í¬ë¡¤ëŸ¬
â”‚   â”œâ”€â”€ wanted_crawler.py     # ì›í‹°ë“œ í¬ë¡¤ëŸ¬
â”‚   â”œâ”€â”€ saramin_crawler.py    # ì‚¬ëŒì¸ í¬ë¡¤ëŸ¬
â”‚   â”œâ”€â”€ jobkorea_crawler.py   # ì¡ì½”ë¦¬ì•„ í¬ë¡¤ëŸ¬
â”‚   â””â”€â”€ rocketpunch_crawler.py # ë¡œì¼“í€ì¹˜ í¬ë¡¤ëŸ¬
â”œâ”€â”€ analyzers/
â”‚   â”œâ”€â”€ market_analyzer.py   # ì‹œì¥ ë¶„ì„
â”‚   â”œâ”€â”€ company_analyzer.py  # íšŒì‚¬ ë¶„ì„
â”‚   â””â”€â”€ llm_analyzer.py      # LLM ê¸°ë°˜ ë¶„ì„
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ database.py          # ë°ì´í„°ë² ì´ìŠ¤ ORM
â”‚   â””â”€â”€ helpers.py           # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
â”œâ”€â”€ main.py              # ë©”ì¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ scheduler.py         # ìë™ ìŠ¤ì¼€ì¤„ëŸ¬
â”œâ”€â”€ report_generator.py  # ë¦¬í¬íŠ¸ ìƒì„±ê¸°
â”œâ”€â”€ data/                # SQLite DB ì €ì¥
â”œâ”€â”€ reports/             # ìƒì„±ëœ ë¦¬í¬íŠ¸
â””â”€â”€ logs/                # ë¡œê·¸ íŒŒì¼
```

## âš™ï¸ ì„¤ì •

### í™˜ê²½ë³€ìˆ˜

| ë³€ìˆ˜ | ê¸°ë³¸ê°’ | ì„¤ëª… |
|------|--------|------|
| `DB_TYPE` | `sqlite` | ë°ì´í„°ë² ì´ìŠ¤ ì¢…ë¥˜ (`sqlite` ë˜ëŠ” `postgresql`) |
| `PG_HOST` | `localhost` | PostgreSQL í˜¸ìŠ¤íŠ¸ |
| `PG_PORT` | `5432` | PostgreSQL í¬íŠ¸ |
| `PG_DATABASE` | `job_market` | PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ |
| `PG_USER` | `postgres` | PostgreSQL ì‚¬ìš©ì |
| `PG_PASSWORD` | - | PostgreSQL ë¹„ë°€ë²ˆí˜¸ |
| `ANTHROPIC_API_KEY` | - | Claude API í‚¤ |
| `OPENAI_API_KEY` | - | OpenAI API í‚¤ (ëŒ€ì²´) |
| `LLM_PROVIDER` | `anthropic` | LLM ì œê³µì |
| `SCHEDULER_TIME` | `09:00` | ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰ ì‹œê°„ |
| `SCHEDULER_TIMEZONE` | `Asia/Seoul` | íƒ€ì„ì¡´ |

### ì„¤ì • íŒŒì¼ (config.json)

```json
{
  "keywords": ["ë°ì´í„° ë¶„ì„ê°€", "ë°±ì—”ë“œ ê°œë°œì", "í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œì"],
  "sites": {
    "linkedin": true,
    "wanted": true,
    "jobkorea": true,
    "saramin": true,
    "rocketpunch": true
  },
  "crawler": {
    "request_delay": 2.0,
    "max_retries": 3,
    "max_pages_per_keyword": 10
  }
}
```

## ğŸ“Š ì‚¬ìš© ì˜ˆì‹œ

### Pythonì—ì„œ ì§ì ‘ ì‚¬ìš©

```python
from config.settings import Settings
from utils.database import Database
from crawlers import get_crawler
from analyzers.market_analyzer import MarketAnalyzer
from analyzers.llm_analyzer import LLMAnalyzer

# ì„¤ì • ë° DB ì´ˆê¸°í™”
settings = Settings()
db = Database(settings.database.connection_string)
db.create_tables()

# í¬ë¡¤ë§
crawler = get_crawler('wanted')
jobs = crawler.crawl_keyword('ë°ì´í„° ë¶„ì„ê°€')
for job in jobs:
    db.add_job_posting(job)

# ì‹œì¥ ë¶„ì„
analyzer = MarketAnalyzer(db)
analysis = analyzer.analyze_keyword('ë°ì´í„° ë¶„ì„ê°€', days=30)
print(f"ì´ {analysis['total_postings']}ê°œ ì±„ìš©ê³µê³ ")
print(f"ìƒìœ„ ìŠ¤í‚¬: {[s['skill'] for s in analysis['skill_analysis']['hard_skills'][:5]]}")

# AI ë¡œë“œë§µ ìƒì„±
llm = LLMAnalyzer()
if llm.is_available():
    roadmap = llm.generate_career_roadmap(
        'ë°ì´í„° ë¶„ì„ê°€',
        analysis['skill_analysis'],
        duration_months=6
    )
    print(roadmap['roadmap_3_months'])
```

### CLI ì˜µì…˜

```bash
# íŠ¹ì • í‚¤ì›Œë“œë§Œ í¬ë¡¤ë§
python main.py crawl --keywords "ë°ì´í„° ë¶„ì„ê°€" "ë°±ì—”ë“œ ê°œë°œì"

# íŠ¹ì • ì‚¬ì´íŠ¸ë§Œ ì‚¬ìš©
python main.py crawl --sites linkedin wanted rocketpunch

# ì„¤ì • íŒŒì¼ ì§€ì •
python main.py --config my_config.json all

# ë””ë²„ê·¸ ëª¨ë“œ
python main.py --debug all
```

### ìŠ¤ì¼€ì¤„ëŸ¬ ì˜µì…˜

```bash
# ê¸°ë³¸: ë§¤ì¼ 09:00 ì‹¤í–‰
python main.py schedule

# ì‹œê°„ ì§€ì •
python scheduler.py --hour 8 --minute 30

# ì¦‰ì‹œ ì‹¤í–‰ í›„ ìŠ¤ì¼€ì¤„ ì‹œì‘
python scheduler.py --run-now

# í‰ì¼ë§Œ ì‹¤í–‰
python scheduler.py --mode weekday

# 6ì‹œê°„ ê°„ê²© ì‹¤í–‰
python scheduler.py --mode interval --interval-hours 6
```

## ğŸ“ ì¶œë ¥ ì˜ˆì‹œ

### ì‹œì¥ ë¶„ì„ ìš”ì•½

```
## ë°ì´í„° ë¶„ì„ê°€ ì±„ìš© ì‹œì¥ ë¶„ì„

### ê¸°ë³¸ í†µê³„
- ì´ ì±„ìš©ê³µê³ : 1,234ê°œ
- ê³ ìœ  ê¸°ì—…: 456ê°œ
- ë¶„ì„ ê¸°ê°„: 2025-01-01 ~ 2025-01-30

### ìƒìœ„ ì±„ìš© ê¸°ì—…
1. ì¹´ì¹´ì˜¤ (45ê±´)
2. ë„¤ì´ë²„ (38ê±´)
3. ì¿ íŒ¡ (32ê±´)

### ìƒìœ„ ê¸°ìˆ  ìŠ¤íƒ
1. Python (78.5%)
2. SQL (72.3%)
3. Pandas (45.2%)
4. Tableau (38.1%)
5. AWS (35.4%)
```

### 3ê°œì›” ë¡œë“œë§µ (AI ìƒì„±)

```
## 3ê°œì›” ì»¤ë¦¬ì–´ ë¡œë“œë§µ: ë°ì´í„° ë¶„ì„ê°€

### 1ì£¼ì°¨-2ì£¼ì°¨: Python ê¸°ì´ˆ
- ëª©í‘œ: Python ë¬¸ë²•, ìë£Œêµ¬ì¡° ì™„ì „ ìˆ™ë‹¬
- ì‹¤ìŠµ: ê°„ë‹¨í•œ ë°ì´í„° ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
- ì¶”ì²œ ìë£Œ: ì í”„ íˆ¬ íŒŒì´ì¬, Codecademy

### 3ì£¼ì°¨-4ì£¼ì°¨: ë°ì´í„° ì²˜ë¦¬
- ëª©í‘œ: Pandas, NumPy ê¸°ë³¸ ì‚¬ìš©ë²•
- ì‹¤ìŠµ: ê³µê³µë°ì´í„° ë¶„ì„ í”„ë¡œì íŠ¸
...
```

## ğŸ”§ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### í¬ë¡¤ë§ ì˜¤ë¥˜

```bash
# ìš”ì²­ ë”œë ˆì´ ëŠ˜ë¦¬ê¸°
export CRAWLER_DELAY=3.0

# íŠ¹ì • ì‚¬ì´íŠ¸ ì œì™¸
python main.py crawl --sites wanted programmers
```

### DB ì—°ê²° ì˜¤ë¥˜

```bash
# SQLite ì‚¬ìš© (ê¸°ë³¸)
export DB_TYPE=sqlite

# PostgreSQL ì—°ê²° í™•ì¸
psql -h localhost -U postgres -d job_market
```

### LLM API ì˜¤ë¥˜

```bash
# API í‚¤ í™•ì¸
echo $ANTHROPIC_API_KEY

# Fallback ëª¨ë“œ ì‚¬ìš© (API ì—†ì´)
# LLM APIê°€ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ í…œí”Œë¦¿ ê¸°ë°˜ ë¡œë“œë§µ ìƒì„±
```

## ğŸ“„ ë¼ì´ì„ ìŠ¤

MIT License

## ğŸ¤ ê¸°ì—¬

ì´ìŠˆ ë° PR í™˜ì˜í•©ë‹ˆë‹¤!
